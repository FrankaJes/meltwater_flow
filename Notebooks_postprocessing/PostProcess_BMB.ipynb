{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean as cmo\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import LightSource\n",
    "from matplotlib import cm\n",
    "\n",
    "import statsmodels.api as sm            # to build a LOWESS model\n",
    "from scipy.interpolate import interp1d  # for interpolation of new data points\n",
    "lowess = sm.nonparametric.lowess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to compute average BMB, average BMB in deep part, and flux\n",
    "def find_BMB_average(ds_hf, add_to_xarray=False, save_to_netcdf=False, savepath=None):\n",
    "\n",
    "    # Create empty array, same length as time array\n",
    "    BMB__av      = np.zeros([len(ds_hf.time.values)])\n",
    "    BMB__av_deep = np.zeros([len(ds_hf.time.values)])\n",
    "\n",
    "    # For the integrated melt flux: take BMB sum\n",
    "    BMB__flux    = ds_hf.BMB.sum(dim=['x','y'], skipna=True)*2000*2000*910*10**(-12)\n",
    "\n",
    "    # Iterate over all time steps in output\n",
    "    for i,t in enumerate(ds_hf.time.values):\n",
    "        BMB__av[i]      = np.nanmean(xr.where(ds_hf.sel(time=t).mask==4, ds_hf.sel(time=t)['BMB'], np.nan).values)\n",
    "        BMB__av_deep[i] = np.nanmean(xr.where(np.logical_and(ds_hf.sel(time=t).mask==4, ds_hf.sel(time=t).Hs-ds_hf.sel(time=t).Hi<-300), ds_hf.sel(time=t)['BMB'], np.nan).values)\n",
    "\n",
    "    # Add to the file if wanted\n",
    "    if add_to_xarray == True:\n",
    "        ds_hf = ds_hf.assign(BMB_av     =(('time'), BMB__av))\n",
    "        ds_hf = ds_hf.assign(BMB_av_deep=(('time'), BMB__av_deep))\n",
    "        ds_hf = ds_hf.assign(BMB_flux   =(('time'), BMB__flux.values))\n",
    "\n",
    "        ds_BMB = ds_hf[['BMB_av', 'BMB_av_deep', 'BMB_flux']]\n",
    "\n",
    "        # Save to netcdf file if wanted\n",
    "        if save_to_netcdf == True:\n",
    "            print('saving to...', savepath)\n",
    "            ds_BMB.to_netcdf(savepath)\n",
    "\n",
    "    return BMB__av, BMB__av_deep, BMB__flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing loop for MAIN runs and RETUNED runs\n",
    "dir = '/Volumes/T7/P1_DIR/Model_output/NOcalving/' #'/Users/5941962/surfdrive/P1_DIR/Model_output'\n",
    "exp_names = [ \n",
    "\n",
    "    #MAIN RUNS\n",
    "    'P1_MEDIUM_QUAD_NOcalving',\n",
    "    'P1_MEDIUM_PICO_NOcalving_C023', \n",
    "    'P1_MEDIUM_PLUME_NOcalving',\n",
    "    'P1_MEDIUM_laddie_NOcalving_rhoice_concat',\n",
    "\n",
    "    'P1_WARM_QUAD_NOcalving_modtune',\n",
    "    'P1_WARM_PICO_NOcalving_C023_modtune', \n",
    "    'P1_WARM_PLUME_NOcalving_modtune',\n",
    "    'P1_WARM_laddie_NOcalving_rhoice_concat', \n",
    "\n",
    "    #RETUNED RUNS\n",
    "    'P1_MEDIUM_QUAD_NOcalving_hightune', \n",
    "    'P1_MEDIUM_PICO_NOcalving_C023_hightune', \n",
    "    'P1_MEDIUM_PLUME_NOcalving_hightune', \n",
    "\n",
    "    'P1_WARM_QUAD_NOcalving',\n",
    "    'P1_WARM_PICO_NOcalving_C023', \n",
    "    'P1_WARM_PLUME_NOcalving',\n",
    "]\n",
    "\n",
    "filename = 'help_fields_ANT.nc'\n",
    "combined_list = [f'{dir}/{exp_name}/{filename}' for exp_name in exp_names]\n",
    "\n",
    "\n",
    "for i in range(len(combined_list)):\n",
    "\n",
    "    print(f'Started computation BMB averages and integrated flux for {exp_names[i]} ...')\n",
    "\n",
    "    # Open file\n",
    "    ds = xr.open_dataset(f'{dir}/{exp_names[i]}/{filename}')\n",
    "\n",
    "    # Compute exact grounding line position from f_grnd\n",
    "    find_BMB_average(ds, add_to_xarray=True, save_to_netcdf=True, savepath=f'../PostProcess/BMB_{exp_names[i]}.nc')\n",
    "\n",
    "    print(f'... DONE')\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing loop for CONTROL & CALVING runs\n",
    "dir = '/Volumes/T7/P1_DIR/Model_output/' #'/Users/5941962/surfdrive/P1_DIR/Model_output'\n",
    "exp_names = [ \n",
    "    #CONTROL RUN\n",
    "    'P1_control',\n",
    "    \n",
    "    #CALVING\n",
    "    'P1_WARM_QUAD_modtune',\n",
    "    'P1_WARM_PICO_C023_modtune', \n",
    "    'P1_WARM_PLUME_modtune',\n",
    "    'P1_WARM_laddie_rhoice_concat', \n",
    "\n",
    "    'P1_MEDIUM_QUAD',\n",
    "    'P1_MEDIUM_PICO_C023', \n",
    "    'P1_MEDIUM_PLUME',\n",
    "    'P1_MEDIUM_laddie_rhoice_concat',\n",
    "]\n",
    "\n",
    "filename = 'help_fields_ANT.nc'\n",
    "combined_list = [f'{dir}/{exp_name}/{filename}' for exp_name in exp_names]\n",
    "\n",
    "\n",
    "for i in range(len(combined_list)):\n",
    "\n",
    "    print(f'Started computation BMB averages and integrated flux for {exp_names[i]} ...')\n",
    "\n",
    "    # Open file\n",
    "    ds = xr.open_dataset(f'{dir}/{exp_names[i]}/{filename}')\n",
    "\n",
    "    # Compute exact grounding line position from f_grnd\n",
    "    find_BMB_average(ds, add_to_xarray=True, save_to_netcdf=True, savepath=f'../PostProcess/BMB_{exp_names[i]}.nc')\n",
    "\n",
    "    print(f'... DONE')\n",
    "    ds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
